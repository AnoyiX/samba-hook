# Samba Hook

å°† SambaNova Cloud Playground è½¬åŒ–æˆæœ¬åœ° API æœåŠ¡ï¼Œç”¨äºå…¶ä»– LLM å®¢æˆ·ç«¯è°ƒç”¨ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### è¿è¡Œ

ä½¿ç”¨ Docker å¯åŠ¨æœåŠ¡ï¼š

```bash
docker run -d \
    -p 8000:8000 \
    -e SAMBA_TOKEN=xxx \
    anoyi/samba-hook:latest
```

ç¯å¢ƒå˜é‡è¯´æ˜ï¼š

| ç¯å¢ƒå˜é‡        | ç±»å‹   | é»˜è®¤å€¼ | å¿…å¡« | æè¿°                                      |
| --------------- | ------ | ------ | ---- | ----------------------------------------- |
| SAMBA_TOKEN     | string |        | å¦   | SambaNova Cloud Cookies ä¸­çš„ access_token |
| SAMBA_TOKEN_API | string |        | å¦   | è·å– SambaNova Cloud access_token çš„API   |

å¦‚æœä¸æä¾› `SAMBA_TOKEN`ï¼Œåˆ™éœ€è¦æä¾› `SAMBA_TOKEN_API`ï¼Œç”¨äºè·å– access_tokenã€‚`SAMBA_TOKEN_API` å“åº”çš„ç»“æœæ˜¯ access_token çš„çº¯æ–‡æœ¬ã€‚

> ç™»å½• [https://cloud.sambanova.ai/](https://cloud.sambanova.ai/) ï¼Œç„¶åæ‰“å¼€æ§åˆ¶å°è·å– cookies ä¸­çš„ access_tokenã€‚

### API æ–‡æ¡£

- Endpoint: `http://127.0.0.1:8000/v1/chat/completions`
- API Key: `æ— `

**OpenAI SDK ç¤ºä¾‹**

```python
from openai import OpenAI
client = OpenAI(api_key="----", base_url="http://127.0.0.1:8000/v1")
response = client.chat.completions.create(  
    model="DeepSeek-R1",  
    messages=[    
        {"role": "system", "content": ""},  
        {"role": "user", "content": "è®¡ç®— 111 * 222"}  
    ],  
    temperature=0.7,  
    max_tokens=4096,
    stream=True,
)  
```


### æ¨¡å‹åˆ—è¡¨

ç›®å‰æ”¯æŒä»¥ä¸‹æ¨¡å‹ï¼š

- DeepSeek-V3.1
- DeepSeek-R1-0528
- DeepSeek-R1-Distill-Llama-70B
- DeepSeek-V3-0324
- E5-Mistral-7B-Instruct
- Llama-3.3-Swallow-70B-Instruct-v0.4
- Llama-4-Maverick-17B-128E-Instruct
- Meta-Llama-3.1-8B-Instruct
- Meta-Llama-3.3-70B-Instruct
- Qwen3-32B
- Whisper-Large-v3

## â“ å¸¸è§é—®é¢˜

### ğŸ’ Samba Hook x Cherry Studio

![](./imgs/cherry-studio.png)

åœ¨ Cherry Studio ä¸­æ·»åŠ æ¨¡å‹æä¾›å•†ï¼š
- åç§° `SambaHook`
- ç±»å‹ `OpenAI`
- API å¯†é’¥ï¼šéšä¾¿å¡«
- API åœ°å€ï¼š`http://127.0.0.1:8000`
- æ¨¡å‹ï¼šæŒ‰ä¸Šè¿°æ¨¡å‹åˆ—è¡¨æ·»åŠ å³å¯