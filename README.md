# Samba Hook

å°† SambaNova Cloud Playground è½¬åŒ–æˆæœ¬åœ° API æœåŠ¡ï¼Œç”¨äºå…¶ä»– LLM å®¢æˆ·ç«¯è°ƒç”¨ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### è¿è¡Œ

ä½¿ç”¨ Docker å¯åŠ¨æœåŠ¡ï¼š

```bash
docker run -d -p 8000:8000 --name samba anoyi/samba-hook:latest
```

ç¯å¢ƒå˜é‡è¯´æ˜ï¼š

| ç¯å¢ƒå˜é‡    | ç±»å‹   | é»˜è®¤å€¼ | å¿…å¡« | æè¿°                                |
| ----------- | ------ | ------ | ---- | ----------------------------------- |
| HTTPS_PROXY | string |        | å¦   | ä»£ç†åœ°å€ï¼Œæ ¼å¼ä¸º `http://host:port` |


### API æ–‡æ¡£

- Endpoint: `http://127.0.0.1:8000/v1/chat/completions`
- API Key: `å¡«å†™ SambaNova Cloud Playground ä¸­çš„ access_token`

> [!IMPORTANT]
>  API Key è·å–æ–¹å¼ï¼šç™»å½• [https://cloud.sambanova.ai/](https://cloud.sambanova.ai/) ï¼Œç„¶åæ‰“å¼€æ§åˆ¶å°è·å– cookies ä¸­çš„ access_tokenã€‚

**OpenAI SDK ç¤ºä¾‹**

```python
from openai import OpenAI
client = OpenAI(api_key="******************", base_url="http://127.0.0.1:8000/v1")
response = client.chat.completions.create(  
    model="DeepSeek-R1",  
    messages=[    
        {"role": "system", "content": ""},  
        {"role": "user", "content": "è®¡ç®— 111 * 222"}  
    ],  
    temperature=0.7,  
    max_tokens=4096,
    stream=True,
)  
```

### æ¨¡å‹åˆ—è¡¨

Reasoning
- DeepSeek-R1-0528
- DeepSeek-R1-Distill-Llama-70B
- DeepSeek-V3.1
- DeepSeek-V3.1-Terminus
- gpt-oss-120b
- Qwen3-235B
- Qwen3-32B

Text
- ALLaM-7B-Instruct-preview
- DeepSeek-V3-0324
- Llama-3.3-Swallow-70B-Instruct-v0.4
- Meta-Llama-3.1-8B-Instruct
- Meta-Llama-3.3-70B-Instruct

Image/Text
- Llama-4-Maverick-17B-128E-Instruct

Audio/Text
- Whisper-Large-v3

## â“ å¸¸è§é—®é¢˜

### ğŸ’ Samba Hook x Cherry Studio

![](./imgs/cherry-studio.png)

åœ¨ Cherry Studio ä¸­æ·»åŠ æ¨¡å‹æä¾›å•†ï¼š
- åç§° `SambaHook`
- ç±»å‹ `OpenAI`
- API å¯†é’¥ï¼š`SambaNova Cloud Playground ä¸­çš„ access_token`
- API åœ°å€ï¼š`http://127.0.0.1:8000`
- æ¨¡å‹ï¼šæŒ‰ä¸Šè¿°æ¨¡å‹åˆ—è¡¨æ·»åŠ å³å¯